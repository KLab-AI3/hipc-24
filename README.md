# Exploring Algorithmic Design Choices for Low Latency CNN Deployment-HIPC-2024
This repo contains code associated with the paper: "Exploring Algorithmic Design Choices for Low Latency CNN Deployment". It was presented at HIPC 2024 and the text can be found at: https://doi.org/10.1109/HiPC62374.2024.00017.
It contains the SYCL-based implementations of five convolution algorithms (IM2COL, KN2ROW, SMM, Direct, and Depthwise) using Intel oneAPI DPC++ (SYCL) and their integration into three popular CNN models: VGG16, ResNet101, and Inception V4. 
The goal is to evaluate and compare different algorithmic strategies for accelerating CNN convolution layers on NVIDIA GPUs.

---

## üìå Algorithms Implemented

1. **Direct Convolution** ‚Äî Naive nested-loop implementation.
2. **Depthwise Convolution** ‚Äî One kernel per input channel.
3. **Im2col** ‚Äî Column-wise patch flattening + matrix multiplication.
4. **Kn2row** ‚Äî Kernel flattening technique.
5. **SMM (Scalar Matrix Multiplication)** ‚Äî Sparse-aware direct multiplication, baseline for unstructured convolution.

---

## üîß Prerequisites

### ‚úÖ Installation via `requirements.txt` (Python)

Create and activate a virtual environment (optional but recommended):

```bash
python3 -m venv sycl_env
source sycl_env/bin/activate
```

Then install Python dependencies:

```bash
pip install -r requirements.txt
```

> This installs `torch`, `torchvision`, and other required packages.

---

### ‚úÖ System Requirements (HPC with NVIDIA V100)

Before compiling SYCL kernels with oneAPI and targeting CUDA backend, make sure the following modules or system libraries are available:

```bash
module load SYCL/2024.0.1.46
module load CUDA/12.1.1
module load cuDNN/8.9.2.26-CUDA-12.1.1
```

> These provide Intel DPC++ compiler, CUDA libraries, and cuDNN support for GPU execution.

---

## üß† CNN Models with SYCL Acceleration

We replace PyTorch's native `nn.Conv2d` with custom `ConvLayer`, which internally calls SYCL-accelerated convolution kernels using `ctypes`.

The following models are implemented and support all five convolution algorithms:

- ‚úÖ VGG16
- ‚úÖ ResNet101
- ‚úÖ InceptionV4

You can choose the algorithm via command line argument:

### üîß Supported Algorithms

```python
algo = "smm"         # Scalar Matrix Multiplication
algo = "kn2row"      # Kernel to Row flattening
algo = "im2col"      # Image to Column flattening
algo = "direct"      # Naive nested-loop
algo = "depthwise"   # Per-channel depthwise
```

### üöÄ Example Usage

Run VGG16 using `smm` convolution:

```bash
python models/vgg16.py --algo smm
```

Run ResNet101 using `im2col`:

```bash
python models/resnet101.py --algo im2col
```

Run InceptionV4 using `kn2row`:

```bash
python models/inceptionv4.py --algo kn2row
```

Each convolution layer will print its execution time (in seconds), and the model will print the total execution time at the end.

---

## ‚öôÔ∏è Build Instructions

Each algorithm is written in its own `.cpp` file. You can compile any one of them using:

```bash
icpx -fsycl -fsycl-targets=nvptx64-nvidia-cuda \
     -Xsycl-target-backend=nvptx64-nvidia-cuda --cuda-gpu-arch=sm_70 \
     sycl_kernels/SMM.cpp -o smm_conv.so -fPIC -shared -lm
```

Replace `SMM.cpp` with any of the following:

- `Direct.cpp`
- `Depthwise.cpp`
- `Im2col.cpp`
- `Kn2row.cpp`

> `sm_70` is the architecture for NVIDIA V100. Output should be a `.so` shared library.

---

## üöÄ Run SYCL Kernel Executables (Optional)

You can also run the `.out` binaries directly (for kernel testing only):

```bash
./SMM.out
```

These log timing results to a CSV file like:

```
smm_result.csv
```

---

## üìÅ Project File Structure

```bash
.
‚îú‚îÄ‚îÄ sycl_kernels/                     # üîß SYCL convolution kernel implementations
‚îÇ   ‚îú‚îÄ‚îÄ Direct.cpp                    # Direct convolution
‚îÇ   ‚îú‚îÄ‚îÄ Depthwise.cpp                 # Depthwise convolution
‚îÇ   ‚îú‚îÄ‚îÄ Im2col.cpp                    # Im2col + GEMM
‚îÇ   ‚îú‚îÄ‚îÄ Kn2row.cpp                    # Kn2row (GEMM variant)
‚îÇ   ‚îú‚îÄ‚îÄ SMM.cpp                       # Scalar Matrix Multiplication baseline
‚îÇ   ‚îî‚îÄ‚îÄ README.md                     # Compilation & usage for SYCL kernels
‚îÇ
‚îú‚îÄ‚îÄ models/                           # üß† CNN models with swapped conv layers
‚îÇ   ‚îú‚îÄ‚îÄ vgg16.py                      # VGG16 with replaceable SYCL conv layers
‚îÇ   ‚îú‚îÄ‚îÄ resnet101.py                  # ResNet101 with replaceable SYCL conv layers
‚îÇ   ‚îú‚îÄ‚îÄ inceptionv4.py                # InceptionV4 with replaceable SYCL conv layers
‚îÇ   ‚îî‚îÄ‚îÄ README.md                     # Usage instructions for models
‚îÇ                        # PyTorch baseline test script
‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îú‚îÄ‚îÄ README.md                         # Project overview & installation guide
```

---

## üìä Output Format

CSV files are generated for each algorithm with format:

```csv
IC,OC,H,W,KH,KW,pad,stride,time_us
```

---

## üìö Citation

This work is part of the paper:

> **"Exploring Algorithmic Design Choices for Low Latency CNN Deployment"**  
> Changxin Li,  Prof. Sanmukh Kuppannagari ‚Äî Case Western Reserve University

Please cite appropriately if used in academic research.
> @INPROCEEDINGS{10884187,
  author={Li, Changxin and Kuppannagari, Sanmukh},
  booktitle={2024 IEEE 31st International Conference on High Performance Computing, Data, and Analytics (HiPC)}, 
  title={Exploring Algorithmic Design Choices for Low Latency CNN Deployment}, 
  year={2024},
  volume={},
  number={},
  pages={78-88},
  keywords={Machine learning algorithms;Convolution;Graphics processing units;Parallel processing;Prediction algorithms;Hardware;Data models;Convolutional neural networks;Low latency communication;Standards;Algorithmic Design Choices;Convolution Algorithms;Vision Models;Performance Portability},
  doi={10.1109/HiPC62374.2024.00017}}
---

## ‚úÖ Installation Summary

### üêç Step 1: Set Up Python Environment

```bash
python3 -m venv sycl_env
source sycl_env/bin/activate
pip install -r requirements.txt
```

Example `requirements.txt`:

```
torch>=2.4.0
torchvision>=0.15.0
```

---

### ‚öôÔ∏è Step 2: Load System Modules (For V100 HPC)

```bash
module load SYCL/2024.0.1.46
module load CUDA/12.1.1
module load cuDNN/8.9.2.26-CUDA-12.1.1
```

---

### üõ†Ô∏è Step 3: Compile SYCL Kernels

```bash
cd sycl_kernels
icpx -fsycl -fsycl-targets=nvptx64-nvidia-cuda \
     -Xsycl-target-backend=nvptx64-nvidia-cuda --cuda-gpu-arch=sm_70 \
     SMM.cpp -o ../smm_conv.so -fPIC -shared -lm
```

Repeat for other algorithms: `Kn2row.cpp`, `Im2col.cpp`, etc.

---

### üß† Step 4: Run Model with Desired Algorithm

```bash
cd models
python vgg16.py --algo smm
```

Outputs total execution time and per-layer timing.

